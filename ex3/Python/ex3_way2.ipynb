{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One vs All logistic regression model for handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayData(X):\n",
    "    for i in range(28):\n",
    "        plt.subplot(4, 7, i+1)\n",
    "        plt.imshow(X[i].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = np.zeros(z.shape)\n",
    "    g = 1/(1+np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y, _lambda):\n",
    "    m = y.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    J = 0\n",
    "    theta=theta.reshape(n,10)\n",
    "    grad = np.zeros(theta.shape)\n",
    "    \n",
    "    h = sigmoid(X@theta)\n",
    "    J = -1/m * (y*np.log(h)+(1-y)*np.log(1-h)) #-(_lambda/2)*theta[1:,:].T@theta[1:,:])\n",
    "    J = np.sum(J)\n",
    "    grad = ((X.T)@(h-y))/m\n",
    "#     grad[0,:] = 1/m * ((X[:,0]).T@(h-y)) \n",
    "#     grad[1:,:] = 1/m * (X[:,1:].T@(h-y)) + (_lambda/m)*theta[1:,:]\n",
    "    \n",
    "    grad=grad.reshape(-1)\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(theta, X, y, _lambda):\n",
    "    \n",
    "    J = 0\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X@theta)\n",
    "    #J = -1/m * ((y.T@np.log(h) + (1-y).T@np.log(1-h))-(_lambda/2)*theta[1:,:].T@theta[1:,:])\n",
    "    #J = -1/m * (y.T@np.log(h) + (1-y).T@np.log(1-h))\n",
    "    J = -1/m * (y*np.log(h)+(1-y)*np.log(1-h))\n",
    "    J = np.sum(J)\n",
    "    dtheta = ((X.T)@(h-y))/m\n",
    "    \n",
    "    return J, dtheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y ,theta, alpha, _lambda, num_iters):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    J_history = []\n",
    "    dtheta = np.zeros(theta.shape)\n",
    "    \n",
    "    for iter in range(num_iters):\n",
    "        \n",
    "        J,  dtheta= computeCost(theta, X, y, _lambda)\n",
    "        J_history.append(J)\n",
    "        \n",
    "        theta = theta - alpha*dtheta\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, num_labels, _lambda):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    all_theta = np.zeros((n+1, num_labels))\n",
    "    \n",
    "    X = np.append(np.ones((m,1)), X, axis=1)\n",
    "    theta_0 = np.zeros((n+1, num_labels))\n",
    "    J = lambda theta: costFunction(theta, X, y, _lambda)[0]\n",
    "    dJ = lambda theta: costFunction(theta, X, y, _lambda)[1]\n",
    "    all_theta = optimize.fmin_cg(J, theta_0, fprime=dJ, maxiter=400,gtol=0.0001,callback=call_back_fminc)\n",
    "    \n",
    "    return all_theta.reshape(n+1,num_labels)\n",
    "\n",
    "itera = 0\n",
    "X_ = np.append(np.ones((m,1)), X, axis=1)\n",
    "J_ = lambda theta: costFunction(theta, X_, labels, 0)[0]\n",
    "                     \n",
    "def call_back_fminc(theta):\n",
    "    global itera\n",
    "    tqdm_train.set_description(f'loss : {J_(theta):.4f} iter: {itera+1}')\n",
    "    itera += 1    \n",
    "    tqdm_train.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta):\n",
    "    m = X.shape[0]\n",
    "    num_labels = theta.shape[0]\n",
    "    \n",
    "    p = np.zeros((X.shape[0], 1))\n",
    "    \n",
    "    X = np.append(np.ones((m,1)), X, axis=1)\n",
    "    \n",
    "    \n",
    "    h = sigmoid(X@theta)\n",
    "    \n",
    "    p = np.argmax(h, axis=1)\n",
    "    \n",
    "    return p.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.datasets import load_digits\n",
    "# from scipy import optimize\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "# digits = load_digits()\n",
    "\n",
    "# X = digits.data\n",
    "# y = digits.target.reshape(-1, 1)\n",
    "\n",
    "# displayData(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "X_t = torch.from_numpy(X)\n",
    "X_t = torch.cat([torch.ones(m,1,dtype=X_t.dtype), X_t], dim=1).float()\n",
    "y_t = torch.eye(10)[torch.from_numpy(y)].squeeze().float()\n",
    "theta = torch.zeros(X_t.shape[1], 10, dtype=X_t.dtype, requires_grad=True)\n",
    "\n",
    "l = X_t.mm(theta)\n",
    "nl = torch.sigmoid(l)\n",
    "\n",
    "loss = - 1/m * (y_t*torch.log(nl) + (1-y_t)*torch.log(1-nl))\n",
    "loss.sum().backward()\n",
    "theta_grad = theta.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.concatenate([np.ones((m,1)), X], axis=1)\n",
    "theta0 = np.zeros((X_.shape[1], 10))\n",
    "y_ = np.eye(10)[y].squeeze()\n",
    "loss_, grad_ = computeCost(theta0, X_, y_, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.931519031524658, 6.931471805599455)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum().item(), loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.481070835328663e-05"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(grad_ - theta_grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# theta_0 = np.zeros((X_.shape[1]*10))\n",
    "# grad_apr = np.zeros_like(theta_0)\n",
    "# perturb = np.zeros_like(theta_0)\n",
    "# e = 0.001\n",
    "# J = lambda theta: costFunction(theta, X_, y_, 0)[0]\n",
    "# # dJ = lambda theta: costFunction(theta, X, y, _lambda)[1]\n",
    "\n",
    "# for i in tqdm(range(len(theta_0))):\n",
    "#     perturb[i] = e\n",
    "#     grad_apr[i] =  J(theta_0 + perturb) - J(theta_0 - perturb) \n",
    "#     grad_apr[i] /= (2*e)\n",
    "#     perturb[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4810708511535781e-05"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(grad_apr.reshape(-1,10) - theta_grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbea3530c0d4f6ab9f91c074ec95975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in multiply\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.152575\n",
      "         Iterations: 400\n",
      "         Function evaluations: 641\n",
      "         Gradient evaluations: 641\n"
     ]
    }
   ],
   "source": [
    "m = digits.data.shape[0]\n",
    "\n",
    "input_layer_size = m\n",
    "num_labels = 10\n",
    "\n",
    "labels=np.unique(y)\n",
    "\n",
    "labels=label_binarize(y, classes=labels)\n",
    "tqdm_train = tqdm(total=400,\n",
    "                     position=0)\n",
    "\n",
    "_lambda = 0\n",
    "\n",
    "all_theta = train(X, labels, num_labels, _lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting for all training examples and calculating the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  99.27657206455203 %\n"
     ]
    }
   ],
   "source": [
    "y_predict = predict(X, all_theta)\n",
    "print('train accuracy: ',np.mean(1*(y_predict==y))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting for one random training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'predicted: 3')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random = np.random.randint(m)\n",
    "example = X[random].reshape(1,-1)\n",
    "predicted = predict(example, all_theta).item()\n",
    "plt.imshow(example.reshape(8,8))\n",
    "plt.title('predicted: '+str(predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
